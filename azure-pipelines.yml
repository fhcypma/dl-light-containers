pool:
  vmImage: ubuntu-latest

variables:
  image-name: spark-on-lambda
  tag: '$(Build.BuildId)-ci'
  region: eu-west-1


stages:

# - stage: Deploy
#   jobs:
#   - job: Cdk
#     displayName: "Cdk deploy"
#     steps:
#     - task: UsePythonVersion@0
#       inputs:
#         versionSpec: '3.9'
#       displayName: 'Use Python 3.9'

#     - task: NodeTool@0
#       inputs:
#         versionSpec: '14.x'
#       displayName: 'Install 14.x'

#     - script: |
#         sudo npm install -g aws-cdk
#         cdk --version
#       displayName: 'Installing aws cdk'

#     - task: PipAuthenticate@1
#       displayName: 'Pip Authenticate'
#       inputs:
#         artifactFeeds: 'dl-light/dl-light'
#         # Setting this variable to "true" will force pip to get distributions from official python registry first and fallback to feeds mentioned above if distributions are not found there.
#         onlyAddExtraIndex: true

#     # Added a workaround for installing the project feed package
#     - script: |
#         python -m pip install pipenv
#         python -m pip install dl-light-infra --index $(PIP_EXTRA_INDEX_URL)
#         python -m pipenv requirements > requirements.txt
#         python -m pip install -r requirements.txt
#       displayName: "Install dependencies"

#     - task: AWSShellScript@1
#       inputs:
#         awsCredentials: yds-deploy
#         regionName: $(region)
#         scriptType: inline
#         inlineScript: |
#           DYNACONF_BUILD_NUMBER="$(Build.BuildNumber)" cdk deploy ContainerStack --require-approval never
#         workingDirectory: $(System.DefaultWorkingDirectory)
#       displayName: "Cdk deploy"

- stage: Publish
  # dependsOn: Deploy
  jobs:
  - job: Build
    displayName: "Spark-on-lambda docker build and push"
    steps:

    # # Pulling before building, using cache for faster build
    # - task: ECRPullImage@1
    #   displayName: "Pull latest from ECR"
    #   inputs:
    #     awsCredentials: yds-deploy
    #     regionName: $(region)
    #     repository: $(image-name)
    #     imageTag: latest
    #   continueOnError: true # for first build, no cache
    - task: Cache@2
      displayName: Enable docker cache
      inputs:
        key: 'docker | "$(Agent.OS)" | cache'
        path: $(Pipeline.Workspace)/docker
        cacheHitVar: CACHE_RESTORED                #Variable to set to 'true' when the cache is restored

    - script: |
        docker load -i $(Pipeline.Workspace)/docker/cache.tar
      displayName: Restore docker layers from cache
      condition: and(not(canceled()), eq(variables.CACHE_RESTORED, 'true'))

    - task: Docker@2
      displayName: Docker build
      inputs:
        command: build
        Dockerfile: spark-on-lambda/Dockerfile
        repository: $(image-name)
        tags: $(tag)

    - script: |
        mkdir -p $(Pipeline.Workspace)/docker
        docker save -o $(Pipeline.Workspace)/docker/cache.tar $(image-name):$(tag)
      displayName: Save docker image to cache
      condition: and(not(canceled()), or(failed(), ne(variables.CACHE_RESTORED, 'true')))

    - task: ECRPushImage@1
      displayName: Push to ECR
      inputs:
        awsCredentials: yds-deploy
        regionName: $(region)
        imageSource: 'imagename'
        sourceImageName: $(image-name)
        sourceImageTag: $(tag)
        repositoryName: $(image-name)
        pushTag: $(tag)


    # - task: AWSShellScript@1
    #   inputs:
    #     awsCredentials: yds-deploy
    #     regionName: $(region)
    #     scriptType: inline
    #     inlineScript: |
    #       AWS_ACCOUNT_ID=$((aws sts get-caller-identity --query "Account" --output text))
    #       # ECR_REPOSITORY_URL="$AWS_ACCOUNT_ID.dkr.ecr.$(region).amazonaws.com"
    #       # aws ecr get-login-password --region "$(region)" | docker login --username AWS --password-stdin "$ECR_REPOSITORY_URL"
    #       # Pulling before building, so we already have certain (or all) layers
    #       # docker pull "$(image-name):latest" || echo "No latest image available"
    #     workingDirectory: $(System.DefaultWorkingDirectory)
    #   displayName: "Pull latest"

#     steps:
#     - task: Docker@2
#       displayName: Build image
#       inputs:
#         repository: $(imageName)
#         command: build
#         Dockerfile: spark-on-labda/Dockerfile

#   - job: Test

#     services:
#       localstack: localstack

#     steps:
#     - task: UsePythonVersion@0
#       inputs:
#         versionSpec: '3.9'
#       displayName: 'Use Python 3.9'

#     - task: PipAuthenticate@1
#       displayName: 'Pip Authenticate'
#       inputs:
#         artifactFeeds: 'dl-light/dl-light'
#         # Setting this variable to "true" will force pip to get distributions from official python registry first and fallback to feeds mentioned above if distributions are not found there.
#         onlyAddExtraIndex: true

#     # Added a workaround for installing the project feed package
#     - script: |
#         python -m pip install pipenv
#         python -m pip install dl-light-infra --index $(PIP_EXTRA_INDEX_URL)
#         python -m pipenv requirements --dev > requirements-dev.txt
#         python -m pip install -r requirements-dev.txt
#       displayName: 'Install dependencies'

#     - script: make code
#       displayName: 'Linting and code formatting check'

#     - script: make test
#       displayName: Test
